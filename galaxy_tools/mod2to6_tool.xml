<?xml version="1.0" encoding="UTF-8"?>
<tool id="module2to6" name="Modules 2–6" version="2.2.3">
  <description>Biomarker discovery per chromosome (pipeline modules 2–6) </description>

  <requirements>
    <requirement type="package" version="0.1.1">cfdna-biomarkersearch</requirement>
    
    <container type="docker">quay.io/biocontainers/cfdna-biomarkersearch:0.1.1--py311h12345_0</container>

    <resource type="ram_min">64000</resource>
    <resource type="cpu_cores_min">50</resource>
  </requirements>

  <command detect_errors="exit_code"><![CDATA[
    mkdir -p working_dir/jars working_dir/config "working_dir/samples/${species}" "working_dir/input/${species}" "working_dir/genome/${species}/hg38" "working_dir/python" "working_dir/ML_output" "working_dir/plot" &&

    echo "subfolders creation inside working directory:" > debug_files_upload.txt &&
    ls -lh working_dir >> debug_files_upload.txt &&

    cp "${aligned_data}" working_dir/samplesdata.tar.gz 2>> debug_files_upload.txt &&
    { tar --strip-components=1 --exclude='._*' -xzf working_dir/samplesdata.tar.gz -C "working_dir/samples/" 2>> debug_files_upload.txt &&
    echo "Samples bam files extraction succeeded" >> debug_files_upload.txt; } || { echo "Samples bam files extraction failed" >> debug_files_upload.txt; } &&
     echo "data samples in working directory:" >> debug_files_upload.txt &&
    ls -lhR working_dir/samples/ >> debug_files_upload.txt &&

    cp "/app/config/log4j2.xml" working_dir/config/log4j2.xml 2>> debug_files_upload.txt &&

    cp "${genome_fasta}" "working_dir/genome/${species}/genome.tar.gz" &&
    { tar --exclude='._*' -xzf working_dir/genome/${species}/genome.tar.gz -C "working_dir/genome/${species}/" 2>> debug_fasta.txt &&
    echo "Genome fasta files extraction succeeded" >> debug_files_upload.txt; } || { echo "Genome fasta files extraction failed" >> debug_files_upload.txt; } &&

    cp -r "/app/python/"* "working_dir/python" 2>> debug_files_upload.txt && 

    { cp "${genomeinfo}" "working_dir/input/${species}/genome.csv" 2>> debug_files_upload.txt &&
    echo "Genome data copy succeeded" >> debug_files_upload.txt; } || { echo "Genome data copy failed" >> debug_files_upload.txt; } &&

    { cp "${parametersinfo}" "working_dir/input/${species}/param.csv" 2>> debug_files_upload.txt &&
    echo "Parameters data copy succeeded" >> debug_files_upload.txt; } || { echo "Parameters data copy failed" >> debug_files_upload.txt; } &&

    echo "inside working directory after copying and extraction:" > pipeline_log.txt &&
    ls -lh working_dir >> pipeline_log.txt &&
    
    CHR=`head -n 1 "${chromosomes}"` &&
    #if $datainfo 
    { cp "${datainfo}" "working_dir/input/${species}/data.csv" 2>> pipeline_log.txt &&
    echo "Samples data copy succeeded" >> debug_files_upload.txt;} &&
    { bash "/app/run_pipeline_module2to6.sh" -o "working_dir" \
    "input/${species}/genome.csv" \
    "input/${species}/param.csv" \
    "input/${species}/data.csv" \
    "${species}" \
    --chromosome "\$CHR";}||
    { echo "pipeline run failed" >> pipeline_log.txt;}
    #else
    echo "No data info provided." >> pipeline_log.txt && 
    { bash "/app/run_pipeline_module2to6.sh" -o "working_dir" \
    "input/${species}/genome.csv" \
    "input/${species}/param.csv" \
    "${species}" \
    --chromosome "\$CHR"; }
    #end if 
    && tar -czf "working_dir/ML_output.tar.gz" -C "working_dir/ML_output" .
    && tar -czf "working_dir/plot.tar.gz" -C "working_dir/plot" .
    && echo "Final working_dir structure:" >> pipeline_log.txt &&
    ls -lhR working_dir >> pipeline_log.txt; 

  ]]></command>

  <inputs>
    <param name="genome_fasta" type="data" format="tar.gz" label="Genome_Fasta" />
    <param name="genomeinfo" type="data" format="csv" label="Genome_Info_CSV" />
    <param name="chromosomes" type="data" format="txt" label="Chromosome_job" />
    <param name="parametersinfo" type="data" format="csv" label="Parameters_Info_CSV" />
    <param name="datainfo" type="data" format="csv" optional="true" label="Data_Info_CSV (optional)" />
    <param name="species" type="text" label="Species" optional="false"/>
    <param name="aligned_data" type="data" format="tar.gz" label="Compressed_Sample_bam_files_Directory" />
  </inputs>

  <outputs>
    <data name="ML_output_dir" format="tar.gz" label="ML_output" from_work_dir="working_dir/ML_output.tar.gz"/>
    <data name="Biomarkers_plots_dir" format="tar.gz" label="Biomarkers_plots" from_work_dir="working_dir/plots.tar.gz"/>
    <data name="debug_output" format="txt" label="Debug_Output_Module2to6" from_work_dir="debug_files_upload.txt"/>
    <data name="script_output" format="txt" label="Pipeline_Log" from_work_dir="pipeline_log.txt"/>
  </outputs>

  <help><![CDATA[
This tool runs **Modules 2–6** of the biomarker discovery pipeline.

### What it does
- Processes aligned BAM files produced by **Module 1**.  
- Uses genome and parameter CSV files provided by the user.  
- Computes Kullback–Leibler (KL) divergence and CNA (copy number alteration) composition for the selected chromosome.  
- Generates intermediate results and plots under `module2to6/` (bundled in debug output).  

### Inputs
- **Genome_Info_CSV**: CSV file containing genome configuration.  
- **Chromosome_job**: Text file specifying the chromosome to process.  
- **Parameters_Info_CSV**: CSV file with pipeline parameters.  
- **Data_Info_CSV (optional)**: CSV file with sample metadata.  
- **Species**: Target species (e.g., `human`, `mouse`).  
- **Compressed_Sample_bam_files_Directory**: `.tar.gz` archive of aligned BAM files (output from Module 1).  

### Outputs
- **Biomarkers_(Module2to6)**: Directory containing all plots generated by the pipeline (number of files may vary).  
- **Pipeline_Log**: Text log of the pipeline run (`log.txt`).  
- **Debug_Output_Module2to6**: Debug information and intermediate results (`debug_files_upload.txt`).

These outputs provide both the computed results and the logs/metrics for troubleshooting, bundled into the debug output.

  ]]></help>
</tool>
